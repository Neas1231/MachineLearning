{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c6afa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import neptune\n",
    "import splitfolders # Библиотека для разделения файлов картинок на train test\n",
    "import matplotlib.gridspec as gridspec\n",
    "cudnn.benchmark = True\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86c74f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/neas1231/Neas1231/e/NEAS-86\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"neas1231/Neas1231\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmY2VjMGIzOS01ZjI1LTQ1MTItODQxYi0zMjIyOWIwYWI0MzIifQ==\",\n",
    ")\n",
    "\n",
    "splitfolders.ratio(\n",
    "    \"E:\\datasets\\dataset-clear\",\n",
    "    output='C:\\data\\dataset\\split',\n",
    "    seed=42,\n",
    "    ratio=(0.7, 0.2, 0.1),\n",
    "    group_prefix=None,\n",
    "    move=False)\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((256 , 256)),   \n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((256 , 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'E:\\datasets\\dataset_noweather'\n",
    "run[\"config/data_dir\"] = data_dir\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "              for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=10,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) \n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92816e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=14):\n",
    "    since = time.time()\n",
    "    #Сохраняем  лучшие веса \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 99\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # перенос  вычислений на куду \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    acc = (torch.sum(preds == labels.data)) / len(inputs)\n",
    "                    run[\"logs/training/batch/loss\"].append(loss)\n",
    "                    run[\"logs/training/batch/acc\"].append(acc)\n",
    "\n",
    "                    # считаем градиенты тольок если трейн данные \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # стасистика  \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # сохраняем не только лучшие веса , но и акураси \n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Loss: {best_loss:4f}')\n",
    "    \n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f81540a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet152(pretrained=True) \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# num_ftrs = model_ft.fc.in_features Для рес нета , но у эфинета другая архитектура \n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "# cuda\n",
    "model_ft = model_ft.to(device)\n",
    "run[\"config/model\"] = model_ft\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "run[\"config/criterion\"] = criterion\n",
    "\n",
    "# оптимайзер  с лернинг рейт \n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "run[\"config/optimizer\"] = optimizer_ft\n",
    "run[\"parameters\"] = model_ft.parameters()\n",
    "\n",
    "# редактируем лернинг рейт каждые 7 шагов \n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed13fc8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.3759 Acc: 0.5176\n",
      "val Loss: 1.1270 Acc: 0.6212\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.9698 Acc: 0.6606\n",
      "val Loss: 0.8102 Acc: 0.7403\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.8354 Acc: 0.7098\n",
      "val Loss: 0.6670 Acc: 0.7816\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.7416\n",
      "val Loss: 0.8302 Acc: 0.7201\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.7245 Acc: 0.7515\n",
      "val Loss: 1.5089 Acc: 0.7416\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.7103 Acc: 0.7605\n",
      "val Loss: 0.8775 Acc: 0.7812\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.7765\n",
      "val Loss: 0.5613 Acc: 0.8074\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.4861 Acc: 0.8327\n",
      "val Loss: 0.4164 Acc: 0.8594\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.4297 Acc: 0.8504\n",
      "val Loss: 0.3909 Acc: 0.8697\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.4085 Acc: 0.8606\n",
      "val Loss: 0.3875 Acc: 0.8732\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.3860 Acc: 0.8685\n",
      "val Loss: 0.3797 Acc: 0.8654\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.3661 Acc: 0.8722\n",
      "val Loss: 0.3657 Acc: 0.8758\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.3499 Acc: 0.8789\n",
      "val Loss: 0.3648 Acc: 0.8805\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.3289 Acc: 0.8832\n",
      "val Loss: 0.3611 Acc: 0.8749\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.3204 Acc: 0.8885\n",
      "val Loss: 0.3588 Acc: 0.8740\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.2971 Acc: 0.8995\n",
      "val Loss: 0.3389 Acc: 0.8835\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.2927 Acc: 0.8977\n",
      "val Loss: 0.3479 Acc: 0.8805\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "Experiencing connection interruptions. Will try to reestablish communication with Neptune. Internal exception was: RequestsFutureAdapterTimeout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:50.986Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:51.584Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:52.182Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:52.780Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:53.377Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:53.975Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:54.571Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/loss. Invalid point: 2023-04-02T13:44:55.174Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:50.986Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:51.584Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:52.182Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:52.780Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:53.378Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:53.975Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:54.571Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: logs/training/batch/acc. Invalid point: 2023-04-02T13:44:55.174Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication with Neptune restored!\n",
      "train Loss: 0.2934 Acc: 0.8985\n",
      "val Loss: 0.3463 Acc: 0.8822\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.2902 Acc: 0.9022\n",
      "val Loss: 0.3558 Acc: 0.8779\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.2911 Acc: 0.9000\n",
      "val Loss: 0.3463 Acc: 0.8826\n",
      "\n",
      "Training complete in 181m 43s\n",
      "Best val Loss: 0.338932\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 2 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 2 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/neas1231/Neas1231/e/NEAS-86/metadata\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)\n",
    "torch.save(model_ft,'resnet152-bestloss-no_weather.pth')\n",
    "torch.save(model_ft.state_dict(), \"weights-resnet152-bestloss-no_weather.pth\")\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c4a5381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19030"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
