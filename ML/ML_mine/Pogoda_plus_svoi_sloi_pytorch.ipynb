{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c6afa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import neptune\n",
    "import splitfolders # Библиотека для разделения файлов картинок на train test\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch.nn.functional as F\n",
    "cudnn.benchmark = True\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86c74f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/neas1231/Neas1231/e/NEAS-106\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"neas1231/Neas1231\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmY2VjMGIzOS01ZjI1LTQ1MTItODQxYi0zMjIyOWIwYWI0MzIifQ==\",\n",
    ")\n",
    "\n",
    "# splitfolders.ratio(\n",
    "#      \"E:\\datasets\\dataset_noweather\",\n",
    "#      output='E:\\datasets\\split',\n",
    "#      seed=42,\n",
    "#      ratio=(0.7, 0.2, 0.1),\n",
    "#      group_prefix=None,\n",
    "#      move=False)\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((128 , 128)),   \n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((128 , 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'E:\\datasets\\split'\n",
    "run[\"config/data_dir\"] = data_dir\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "              for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) \n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92816e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=14):\n",
    "    since = time.time()\n",
    "    #Сохраняем  лучшие веса \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 99\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # перенос  вычислений на куду \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    acc = (torch.sum(preds == labels.data)) / len(inputs)\n",
    "                    run[\"logs/training/batch/loss\"].append(loss)\n",
    "                    run[\"logs/training/batch/acc\"].append(acc)\n",
    "\n",
    "                    # считаем градиенты тольок если трейн данные \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # стасистика  \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # сохраняем не только лучшие веса , но и акураси \n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Loss: {best_loss:4f}')\n",
    "    \n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f81540a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.efficientnet_b4(pretrained=True) \n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "# num_ftrs = model_ft.fc.in_features Для рес нета , но у эфинета другая архитектура \n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "# cuda\n",
    "model_ft = model_ft.to(device)\n",
    "run[\"config/model\"] = model_ft\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "run[\"config/criterion\"] = criterion\n",
    "\n",
    "# оптимайзер  с лернинг рейт \n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "run[\"config/optimizer\"] = optimizer_ft\n",
    "run[\"parameters\"] = model_ft.parameters()\n",
    "\n",
    "# редактируем лернинг рейт каждые 7 шагов \n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed13fc8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.4072 Acc: 0.6272\n",
      "val Loss: 1.4350 Acc: 0.8178\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6200 Acc: 0.8075\n",
      "val Loss: 0.4950 Acc: 0.8551\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4522 Acc: 0.8521\n",
      "val Loss: 0.3852 Acc: 0.8895\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3643 Acc: 0.8843\n",
      "val Loss: 0.4239 Acc: 0.8820\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3138 Acc: 0.8970\n",
      "val Loss: 0.4461 Acc: 0.8839\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2627 Acc: 0.9140\n",
      "val Loss: 0.3919 Acc: 0.8990\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2280 Acc: 0.9222\n",
      "val Loss: 0.5135 Acc: 0.8777\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2094 Acc: 0.9280\n",
      "val Loss: 0.3795 Acc: 0.9037\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1803 Acc: 0.9383\n",
      "val Loss: 0.3762 Acc: 0.8994\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9494\n",
      "val Loss: 0.3729 Acc: 0.9112\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1322 Acc: 0.9545\n",
      "val Loss: 0.3559 Acc: 0.9112\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1165 Acc: 0.9608\n",
      "val Loss: 0.3564 Acc: 0.9136\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1052 Acc: 0.9633\n",
      "val Loss: 0.3745 Acc: 0.9178\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1038 Acc: 0.9627\n",
      "val Loss: 0.3820 Acc: 0.9117\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0799 Acc: 0.9734\n",
      "val Loss: 0.3581 Acc: 0.9103\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0826 Acc: 0.9727\n",
      "val Loss: 0.3510 Acc: 0.9207\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0780 Acc: 0.9753\n",
      "val Loss: 0.3945 Acc: 0.9117\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0791 Acc: 0.9734\n",
      "val Loss: 0.3602 Acc: 0.9155\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0712 Acc: 0.9756\n",
      "val Loss: 0.3539 Acc: 0.9174\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0761 Acc: 0.9762\n",
      "val Loss: 0.3720 Acc: 0.9112\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9766\n",
      "val Loss: 0.3607 Acc: 0.9169\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9749\n",
      "val Loss: 0.3388 Acc: 0.9197\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0767 Acc: 0.9719\n",
      "val Loss: 0.3730 Acc: 0.9164\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0780 Acc: 0.9726\n",
      "val Loss: 0.3590 Acc: 0.9141\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0710 Acc: 0.9761\n",
      "val Loss: 0.3616 Acc: 0.9183\n",
      "\n",
      "Training complete in 40m 48s\n",
      "Best val Loss: 0.338814\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 108 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 108 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/neas1231/Neas1231/e/NEAS-106/metadata\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)\n",
    "torch.save(model_ft,'efficientnet_b4-bestloss-no_weather_new.pth')\n",
    "torch.save(model_ft.state_dict(), \"weights-efficientnet_b4-bestloss-no_weather_new.pth\")\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c4a5381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a069604",
   "metadata": {},
   "source": [
    "### Добавление слоёв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d330ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained = True)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Identity()\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.avgpool = nn.AvgPool2d(5,3)\n",
    "        self.layer = nn.Linear(512, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.exit_layer = nn.Linear(512, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.exit_layer(x)\n",
    "        x = self.sigm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b349ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_add = net()\n",
    "model = nn.Sequential(resnet, net_add)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9865ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.1969 Acc: 0.1803\n",
      "val Loss: 2.1272 Acc: 0.1539\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.2337 Acc: 0.1472\n",
      "val Loss: 2.2149 Acc: 0.2227\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.2634 Acc: 0.1530\n",
      "val Loss: 2.2959 Acc: 0.1174\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 2.3141 Acc: 0.1458\n",
      "val Loss: 2.3124 Acc: 0.1376\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 2.3748 Acc: 0.1060\n",
      "val Loss: 2.3979 Acc: 0.0709\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 2.3980 Acc: 0.0695\n",
      "val Loss: 2.3979 Acc: 0.0735\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer_ft \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      3\u001b[0m exp_lr_scheduler \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_ft, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     42\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# стасистика  \u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     46\u001b[0m     running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44263ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71033ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
