{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b0b0e58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:18.560428500Z",
     "start_time": "2024-01-15T12:17:18.476420700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "\n",
    "def views(x):\n",
    "    return x.view(-1, 784)\n",
    "mnist_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=0.5, std=0.5),\n",
    "                                       transforms.Lambda(views)])\n",
    "\n",
    "data = datasets.MNIST(root='/data/MNIST', download=True, transform=mnist_transforms)\n",
    "\n",
    "mnist_dataloader = DataLoader(data, batch_size=64, shuffle=True, num_workers=0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6c8a0ced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:18.770109900Z",
     "start_time": "2024-01-15T12:17:18.768109100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset MNIST\n    Number of datapoints: 60000\n    Root location: /data/MNIST\n    Split: Train\n    StandardTransform\nTransform: Compose(\n               ToTensor()\n               Normalize(mean=0.5, std=0.5)\n           )"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([64, 1, 28, 28])"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = iter(mnist_dataloader)\n",
    "X = next(test_data)\n",
    "print(len(X))\n",
    "X[0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:19.110859500Z",
     "start_time": "2024-01-15T12:17:19.108859100Z"
    }
   },
   "id": "abb6f915f4a0c9b7"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "743c9b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:19.297501Z",
     "start_time": "2024-01-15T12:17:19.268493400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  '''\n",
    "  Generator class. Accepts a tensor of size 100 as input as outputs another\n",
    "  tensor of size 784. Objective is to generate an output tensor that is\n",
    "  indistinguishable from the real MNIST digits \n",
    "  '''\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(nn.Linear(in_features=128, out_features=256),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer2 = nn.Sequential(nn.Linear(in_features=256, out_features=512),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=1024),\n",
    "                                nn.LeakyReLU())\n",
    "    self.output = nn.Sequential(nn.Linear(in_features=1024, out_features=28*28),\n",
    "                                nn.Tanh())\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0ccfe0ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:19.518749500Z",
     "start_time": "2024-01-15T12:17:19.494743100Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  '''\n",
    "  Discriminator class. Accepts a tensor of size 784 as input and outputs\n",
    "  a tensor of size 1 as  the predicted class probabilities\n",
    "  (generated or real data)\n",
    "  '''\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(nn.Linear(in_features=28*28, out_features=1024),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer2 = nn.Sequential(nn.Linear(in_features=1024, out_features=512),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=256),\n",
    "                                nn.LeakyReLU())\n",
    "    self.output = nn.Sequential(nn.Linear(in_features=256, out_features=1),\n",
    "                                nn.Sigmoid())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "G = Generator()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "D_optimizer =  torch.optim.Adam(D.parameters(), lr=1.0e-3)\n",
    "G_optimizer =  torch.optim.Adam(G.parameters(), lr=1.0e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:20.523925800Z",
     "start_time": "2024-01-15T12:17:20.463215700Z"
    }
   },
   "id": "2821a2eaaea6a13f"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1792x28 and 784x1024)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[178], line 10\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Обучаем дискриминатор\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# real_inputs - изображения из набора данных MNIST \u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# fake_inputs - изображения от генератора\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# real_inputs должны быть классифицированы как 1, а fake_inputs - как 0\u001B[39;00m\n\u001B[0;32m      9\u001B[0m real_inputs \u001B[38;5;241m=\u001B[39m imgs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 10\u001B[0m real_outputs \u001B[38;5;241m=\u001B[39m D(real_inputs)\n\u001B[0;32m     11\u001B[0m real_label \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(real_inputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     12\u001B[0m noise \u001B[38;5;241m=\u001B[39m (torch\u001B[38;5;241m.\u001B[39mrand(real_inputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m128\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m0.5\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[176], line 20\u001B[0m, in \u001B[0;36mDiscriminator.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 20\u001B[0m   x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer1(x)\n\u001B[0;32m     21\u001B[0m   x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[0;32m     22\u001B[0m   x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer3(x)\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1792x28 and 784x1024)"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for idx, (imgs, _) in enumerate(mnist_dataloader):\n",
    "        idx += 1\n",
    "        \n",
    "        # Обучаем дискриминатор\n",
    "        # real_inputs - изображения из набора данных MNIST \n",
    "        # fake_inputs - изображения от генератора\n",
    "        # real_inputs должны быть классифицированы как 1, а fake_inputs - как 0\n",
    "        real_inputs = imgs.to(device)\n",
    "        real_outputs = D(real_inputs)\n",
    "        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n",
    "        noise = (torch.rand(real_inputs.shape[0], 128) - 0.5) / 0.5\n",
    "        noise = noise.to(device)\n",
    "        fake_inputs = G(noise)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n",
    "        outputs = torch.cat((real_outputs, fake_outputs), 0)\n",
    "        targets = torch.cat((real_label, fake_label), 0)\n",
    "        D_loss = loss(outputs, targets)\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        # Обучаем генератор\n",
    "        # Цель генератора получить от дискриминатора 1 по всем изображениям\n",
    "        noise = (torch.rand(real_inputs.shape[0], 128)-0.5)/0.5\n",
    "        noise = noise.to(device)\n",
    "        fake_inputs = G(noise)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\n",
    "        G_loss = loss(fake_outputs, fake_targets)\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        if idx % 100 == 0 or idx == len(mnist_dataloader):\n",
    "            print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, idx, D_loss.item(), G_loss.item()))\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
    "        print('Model saved.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:17:20.874845Z",
     "start_time": "2024-01-15T12:17:20.666492400Z"
    }
   },
   "id": "729bbc3b34035501"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ".torch.randn(100,1,100, device=device).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T12:17:20.874845Z"
    }
   },
   "id": "4d32be4af31b8a9"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cb3d1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T10:09:44.910989900Z",
     "start_time": "2024-01-15T10:08:13.127356500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 1.5 M \n",
      "1 | discriminator | Discriminator | 1.5 M \n",
      "------------------------------------------------\n",
      "2.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.786    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85e0075f6a55420f8002ee09b7fedda6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000023C6465E700> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    " \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # print(1)\n",
    "    self.generator = Generator()\n",
    "    self.discriminator = Discriminator()\n",
    "    # After each epoch, we generate 100 images using the noise\n",
    "    # vector here (self.test_noises). We save the output images\n",
    "    # in a list (self.test_progression) for plotting later.\n",
    "    self.test_noises = torch.randn(100,1,100, device=device)\n",
    "    self.test_progression = []\n",
    "    self.automatic_optimization = False\n",
    "    \n",
    "\n",
    "  def forward(self, z):\n",
    "    \"\"\"\n",
    "    Generates an image using the generator\n",
    "    given input noise z\n",
    "    \"\"\"\n",
    "    #print('2')\n",
    "    return self.generator(z)\n",
    "\n",
    "  def generator_step(self, x):\n",
    "    \"\"\"\n",
    "    Training step for generator\n",
    "    1. Sample random noise\n",
    "    2. Pass noise to generator to\n",
    "       generate images\n",
    "    3. Classify generated images using\n",
    "       the discriminator\n",
    "    4. Backprop loss to the generator\n",
    "    \"\"\"\n",
    "    #print('3')\n",
    "    \n",
    "    # Sample noise\n",
    "    z = torch.randn(x.shape[0], 1, 100, device=device)\n",
    "\n",
    "    # Generate images\n",
    "    generated_imgs = self(z)\n",
    "\n",
    "    # Classify generated images\n",
    "    # using the discriminator\n",
    "    d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
    "\n",
    "    # Backprop loss. We want to maximize the discriminator's\n",
    "    # loss, which is equivalent to minimizing the loss with the true\n",
    "    # labels flipped (i.e. y_true=1 for fake images). We do this\n",
    "    # as PyTorch can only minimize a function instead of maximizing\n",
    "    g_loss = nn.BCELoss()(d_output,\n",
    "                           torch.ones(x.shape[0], device=device))\n",
    "\n",
    "    return g_loss\n",
    "\n",
    "  def discriminator_step(self, x):\n",
    "    #print('4')\n",
    "    \"\"\"\n",
    "    Training step for discriminator\n",
    "    1. Get actual images\n",
    "    2. Predict probabilities of actual images and get BCE loss\n",
    "    3. Get fake images from generator\n",
    "    4. Predict probabilities of fake images and get BCE loss\n",
    "    5. Combine loss from both and backprop loss to discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Real images\n",
    "    d_output = torch.squeeze(self.discriminator(x))\n",
    "    loss_real = nn.BCELoss()(d_output,\n",
    "                             torch.ones(x.shape[0], device=device))\n",
    "\n",
    "    # Fake images\n",
    "    z = torch.randn(x.shape[0], 1, 100, device=device)\n",
    "    generated_imgs = self(z)\n",
    "    d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
    "    loss_fake = nn.BCELoss()(d_output,\n",
    "                             torch.zeros(x.shape[0], device=device))\n",
    "\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    #print('5')\n",
    "    X, _ = batch\n",
    "    plt.imshow(np.reshape(X[0].detach().numpy(),(28,28)))\n",
    "    g_opt, d_opt = self.optimizers()\n",
    "     \n",
    "    g_loss = self.generator_step(X)\n",
    "    g_opt.zero_grad()\n",
    "    self.manual_backward(g_loss)\n",
    "    g_opt.step()\n",
    "    \n",
    "    d_loss = self.discriminator_step(X)\n",
    "    d_opt.zero_grad()\n",
    "    self.manual_backward(d_loss)\n",
    "    d_opt.step()\n",
    "    \n",
    "    #print(g_loss, d_loss)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    #print('6')\n",
    "    g_opt = torch.optim.Adam(self.generator.parameters(), lr=0.001)\n",
    "    d_opt = torch.optim.Adam(self.discriminator.parameters(), lr=0.001)\n",
    "    return g_opt, d_opt\n",
    "\n",
    "  def on_train_epoch_end(self): # , training_step_outputs\n",
    "    #print('7')\n",
    "    epoch_test_images = self(self.test_noises)\n",
    "    self.test_progression.append(epoch_test_images)\n",
    "#Теперь мы можем обучить наш GAN. Мы будем обучать его с помощью графического процессора в течение 100 эпох.\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = GAN()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=2)#, max_epochs=40,accelerator=\"auto\"\n",
    "trainer.fit(model, mnist_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d530e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T07:58:56.309958600Z",
     "start_time": "2024-01-15T07:58:56.289682700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d691ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T10:09:50.853607400Z",
     "start_time": "2024-01-15T10:09:50.788963100Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[114], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(ncol):\n\u001B[0;32m     24\u001B[0m     idx \u001B[38;5;241m=\u001B[39m i\u001B[38;5;241m*\u001B[39mncol \u001B[38;5;241m+\u001B[39m j\n\u001B[1;32m---> 25\u001B[0m     img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(images[epoch_to_plot\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][indexes[idx]], (\u001B[38;5;241m28\u001B[39m,\u001B[38;5;241m28\u001B[39m))\n\u001B[0;32m     26\u001B[0m     ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplot(gs[i,j])\n\u001B[0;32m     27\u001B[0m     ax\u001B[38;5;241m.\u001B[39mimshow(img, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1800x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, gridspec\n",
    "\n",
    "# Convert images from torch tensor to numpy array\n",
    "images = [i.detach().cpu().numpy() for i in model.test_progression]\n",
    "\n",
    "epoch_to_plot = 1\n",
    "nrow = 4\n",
    "ncol = 8\n",
    "\n",
    "# randomly select 10 images for plotting\n",
    "indexes = np.random.choice(range(100), nrow*ncol, replace=False)\n",
    "\n",
    "fig = plt.figure(figsize=((ncol+1)*2, (nrow+1)*2)) \n",
    "fig.suptitle('Epoch {}'.format(epoch_to_plot), fontsize=30)\n",
    "\n",
    "gs = gridspec.GridSpec(nrow, ncol,\n",
    "         wspace=0.0, hspace=0.0, \n",
    "         top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), \n",
    "         left=0.5/(ncol+1), right=1-0.5/(ncol+1)) \n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        idx = i*ncol + j\n",
    "        img = np.reshape(images[epoch_to_plot-1][indexes[idx]], (28,28))\n",
    "        ax = plt.subplot(gs[i,j])\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.        , -1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        , -1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        ,  1.        ,  1.        ,\n         1.        ,  1.        , -1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        , -1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n         1.        ,  1.        ,  1.        , -1.        ,  1.        ,\n        -1.        ,  1.        ,  1.        , -1.        , -1.        ,\n         1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n         1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        , -1.        ],\n       [-1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n         1.        ,  1.        ,  0.99998266, -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ],\n       [ 1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        ,  1.        ,  1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        ,  1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        -1.        , -1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -0.9999999 , -1.        ,  1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        , -1.        , -1.        ,\n         1.        ,  1.        ,  1.        ],\n       [-1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        ,  1.        ,  1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        ,  1.        ,\n         1.        ,  1.        ,  1.        ,  1.        , -1.        ,\n         1.        ,  1.        , -1.        ,  1.        ,  1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        ,  1.        ],\n       [-1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n         1.        ,  1.        ,  1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        , -1.        , -0.9999998 ,  1.        , -1.        ,\n        -0.9999146 ,  1.        ,  1.        ,  1.        , -1.        ,\n        -1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ],\n       [-1.        , -1.        , -1.        ,  0.99999994, -1.        ,\n        -1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        , -1.        ,  1.        ,\n        -1.        , -1.        , -1.        ,  1.        ,  1.        ,\n        -1.        , -1.        , -1.        ,  1.        ,  1.        ,\n         1.        , -1.        , -1.        ],\n       [ 1.        , -1.        , -1.        , -1.        , -1.        ,\n         1.        ,  1.        ,  0.99995935, -1.        ,  1.        ,\n        -1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n         1.        ,  1.        ,  1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ],\n       [-1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ,  1.        ,  1.        ,\n        -1.        , -0.9999998 , -1.        ,  1.        ,  1.        ,\n         1.        ,  1.        ,  1.        , -1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ],\n       [-1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        ,  1.        , -1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n         1.        , -1.        ,  1.        ],\n       [-1.        , -1.        ,  1.        , -1.        , -1.        ,\n         1.        ,  1.        , -1.        ,  1.        ,  1.        ,\n         1.        , -1.        , -1.        ,  1.        ,  1.        ,\n         1.        , -1.        , -1.        ,  1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        ],\n       [-1.        ,  1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        ,  1.        ,  1.        ,  1.        ,\n        -0.99999994, -1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        ,  1.        ,  1.        ,  1.        ,\n         1.        , -1.        ,  1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n         1.        ,  1.        ,  1.        , -1.        ,  1.        ,\n         1.        ,  1.        , -1.        , -1.        ,  1.        ,\n         1.        ,  1.        ,  1.        , -1.        ,  1.        ,\n        -1.        , -1.        ,  1.        ],\n       [-1.        ,  1.        , -1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        ,  1.        ,\n         1.        , -1.        ,  1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ],\n       [-1.        , -1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -0.9999994 ,\n        -1.        , -1.        ,  1.        ,  1.        , -1.        ,\n         1.        , -1.        ,  1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ],\n       [-1.        , -1.        ,  1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n         1.        , -1.        ,  1.        , -1.        ,  1.        ,\n        -1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        ],\n       [-1.        , -1.        ,  1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        , -1.        ,  1.        ,  1.        ,\n        -1.        , -1.        ,  1.        ],\n       [ 1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        ,  1.        , -1.        ,  1.        ,\n        -1.        , -1.        ,  1.        ,  1.        , -1.        ,\n        -1.        ,  1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        ,  1.        ],\n       [ 1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n         1.        , -1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        ,  1.        ,  1.        , -1.        ,\n         1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        ,  1.        ],\n       [-1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        ,  1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n         1.        ,  1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n        -1.        ,  1.        ,  1.        , -1.        ,  1.        ,\n        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        ],\n       [ 1.        ,  1.        ,  1.        , -1.        , -1.        ,\n         1.        , -1.        , -1.        , -1.        , -0.99999994,\n        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n         1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        , -1.        , -1.        ,\n         1.        ,  1.        , -1.        ],\n       [-1.        , -1.        , -1.        , -1.        ,  1.        ,\n         1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        ,  1.        ],\n       [ 1.        , -1.        , -1.        ,  1.        , -1.        ,\n         1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        ,  1.        ,  1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        , -1.        , -1.        ,\n        -1.        , -1.        , -1.        ,  1.        ,  1.        ,\n        -1.        , -1.        , -1.        ]], dtype=float32)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(model.forward(torch.randn(1,1,100)).detach().numpy(),(28,28))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:09:52.711780200Z",
     "start_time": "2024-01-15T10:09:52.667690500Z"
    }
   },
   "id": "bcb22f8d632737f3"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7cce98c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T10:10:28.964049700Z",
     "start_time": "2024-01-15T10:10:28.758150300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x23c7f65b190>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.reshape(model.forward(torch.randn(1,1,100)).detach().numpy(),(28,28))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 5.07983446e-01, -8.56134772e-01,  6.58681750e-01,\n         -5.56978881e-01,  4.59508568e-01, -1.33551195e-01,\n          1.58638585e+00, -3.67085814e-01,  7.08193839e-01,\n          2.05746603e+00,  1.57912719e+00,  3.59650582e-01,\n         -1.55611351e-01, -1.28941405e+00,  8.13412786e-01,\n          3.04984629e-01,  1.17076226e-01, -7.31400728e-01,\n          7.24779218e-02, -2.31657958e+00, -7.45728314e-01,\n         -2.80001462e-01,  8.60050857e-01, -8.50371718e-01,\n          1.25235513e-01,  1.00741494e+00, -2.04857901e-01,\n         -1.15286922e+00,  4.12721694e-01,  1.02843940e+00,\n          4.00168508e-01,  6.34475276e-02,  2.54313052e-01,\n          1.00115073e+00, -8.31082985e-02,  1.27650928e+00,\n          4.12714541e-01, -9.92530659e-02, -1.68523073e+00,\n          2.28361294e-01,  2.34285280e-01,  1.47009119e-01,\n          1.43849182e+00, -1.52908236e-01,  3.79862100e-01,\n         -9.10960436e-01, -9.12463605e-01, -1.11210018e-01,\n         -2.93070078e-01, -3.76423985e-01, -9.69222367e-01,\n          1.49738312e+00,  1.78706503e+00, -8.69702041e-01,\n         -3.68321300e-01, -1.10425329e+00,  1.80981231e+00,\n          1.63566530e+00,  1.76322043e+00,  2.18460023e-01,\n          5.95129251e-01, -4.03650939e-01,  1.65122449e-01,\n          1.15395439e+00, -3.83286923e-01, -1.06520104e+00,\n         -5.86800814e-01,  9.89067554e-01,  2.66157597e-01,\n          4.27363589e-02,  4.66425449e-01,  2.82977067e-04,\n          1.83238924e+00, -7.36143947e-01,  2.22287631e+00,\n          3.43196779e-01,  1.99865755e-02,  2.16169715e+00,\n         -2.08142114e+00,  2.19057846e+00, -5.39361358e-01,\n         -2.57332355e-01, -4.95478123e-01,  9.14765358e-01,\n          9.28966761e-01,  1.35699645e-01,  8.36509287e-01,\n          1.39412925e-01, -1.28176057e+00,  7.12661445e-01,\n         -2.12806487e+00, -1.56371631e-02, -1.24901450e+00,\n         -7.95678854e-01,  2.43408394e+00,  9.05388780e-03,\n          1.35305214e+00,  1.06493044e+00,  5.59496164e-01,\n          7.35745668e-01]]], dtype=float32)"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,1,100).detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:10:15.974156600Z",
     "start_time": "2024-01-15T10:10:15.957276Z"
    }
   },
   "id": "1962714bc97b8f40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c01ff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-15T06:49:18.299530500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "mnist_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=0.5, std=0.5),\n",
    "                                       transforms.Lambda(lambda x: x.view(-1, 784))])\n",
    "\n",
    "data = datasets.MNIST(root='/data/MNIST', download=True, transform=mnist_transforms)\n",
    "\n",
    "mnist_dataloader = DataLoader(data, batch_size=32, shuffle=True, num_workers=0) \n",
    "class Generator(nn.Module):\n",
    "  '''\n",
    "  Generator class. Accepts a tensor of size 100 as input as outputs another\n",
    "  tensor of size 784. Objective is to generate an output tensor that is\n",
    "  indistinguishable from the real MNIST digits \n",
    "  '''\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(nn.Linear(in_features=100, out_features=256),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer2 = nn.Sequential(nn.Linear(in_features=256, out_features=512),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=1024),\n",
    "                                nn.LeakyReLU())\n",
    "    self.output = nn.Sequential(nn.Linear(in_features=1024, out_features=28*28),\n",
    "                                nn.Tanh())\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.output(x)\n",
    "    return x\n",
    "  \n",
    "class Discriminator(nn.Module):\n",
    "  '''\n",
    "  Discriminator class. Accepts a tensor of size 784 as input and outputs\n",
    "  a tensor of size 1 as  the predicted class probabilities\n",
    "  (generated or real data)\n",
    "  '''\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(nn.Linear(in_features=28*28, out_features=1024),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer2 = nn.Sequential(nn.Linear(in_features=1024, out_features=512),\n",
    "                                nn.LeakyReLU())\n",
    "    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=256),\n",
    "                                nn.LeakyReLU())\n",
    "    self.output = nn.Sequential(nn.Linear(in_features=256, out_features=1),\n",
    "                                nn.Sigmoid())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853160ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-15T06:49:18.315160300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.generator = Generator()\n",
    "    self.discriminator = Discriminator()\n",
    "    # After each epoch, we generate 100 images using the noise\n",
    "    # vector here (self.test_noises). We save the output images\n",
    "    # in a list (self.test_progression) for plotting later.\n",
    "    self.test_noises = torch.randn(100,1,100, device=device)\n",
    "    self.test_progression = []\n",
    "\n",
    "  def forward(self, z):\n",
    "    \"\"\"\n",
    "    Generates an image using the generator\n",
    "    given input noise z\n",
    "    \"\"\"\n",
    "    return self.generator(z)\n",
    "\n",
    "  def generator_step(self, x):\n",
    "    \"\"\"\n",
    "    Training step for generator\n",
    "    1. Sample random noise\n",
    "    2. Pass noise to generator to\n",
    "       generate images\n",
    "    3. Classify generated images using\n",
    "       the discriminator\n",
    "    4. Backprop loss to the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample noise\n",
    "    z = torch.randn(x.shape[0], 1, 100, device=device)\n",
    "\n",
    "    # Generate images\n",
    "    generated_imgs = self(z)\n",
    "\n",
    "    # Classify generated images\n",
    "    # using the discriminator\n",
    "    d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
    "\n",
    "    # Backprop loss. We want to maximize the discriminator's\n",
    "    # loss, which is equivalent to minimizing the loss with the true\n",
    "    # labels flipped (i.e. y_true=1 for fake images). We do this\n",
    "    # as PyTorch can only minimize a function instead of maximizing\n",
    "    g_loss = nn.BCELoss()(d_output,\n",
    "                           torch.ones(x.shape[0], device=device))\n",
    "\n",
    "    return g_loss\n",
    "\n",
    "  def discriminator_step(self, x):\n",
    "    \"\"\"\n",
    "    Training step for discriminator\n",
    "    1. Get actual images\n",
    "    2. Predict probabilities of actual images and get BCE loss\n",
    "    3. Get fake images from generator\n",
    "    4. Predict probabilities of fake images and get BCE loss\n",
    "    5. Combine loss from both and backprop loss to discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Real images\n",
    "    d_output = torch.squeeze(self.discriminator(x))\n",
    "    loss_real = nn.BCELoss()(d_output,\n",
    "                             torch.ones(x.shape[0], device=device))\n",
    "\n",
    "    # Fake images\n",
    "    z = torch.randn(x.shape[0], 1, 100, device=device)\n",
    "    generated_imgs = self(z)\n",
    "    d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
    "    loss_fake = nn.BCELoss()(d_output,\n",
    "                             torch.zeros(x.shape[0], device=device))\n",
    "\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "  def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "    X, _ = batch\n",
    "\n",
    "    # train generator\n",
    "    if optimizer_idx == 0:\n",
    "      loss = self.generator_step(X)\n",
    "    \n",
    "    # train discriminator\n",
    "    if optimizer_idx == 1:\n",
    "      loss = self.discriminator_step(X)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.0002)\n",
    "    d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
    "    return [g_optimizer, d_optimizer], []\n",
    "\n",
    "  def on_train_epoch_end(self, training_step_outputs):\n",
    "    epoch_test_images = self(self.test_noises)\n",
    "    self.test_progression.append(epoch_test_images)\n",
    "#Теперь мы можем обучить наш GAN. Мы будем обучать его с помощью графического процессора в течение 100 эпох.\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GAN()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(model, mnist_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82d5f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-15T06:49:18.317591500Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in torch.manual_seed(42):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a042bf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-15T06:49:18.320466900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3fbc68a9c4554ff7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
